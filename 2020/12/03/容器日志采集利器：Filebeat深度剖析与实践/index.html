<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>Filebeat深度剖析与实践-转载(知乎-忽如远行客) [ 木子木木三 ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
  
<meta name="generator" content="Hexo 5.0.2"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          <a href="/">首页</a>
        
          
          
          
          
          
          <a href="/archives">归档</a>
        
          
          
          
          
          
          <a href="/about">关于</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">Filebeat深度剖析与实践-转载(知乎-忽如远行客)</h1>
<article class="post markdown-style">
  <blockquote>
<p><em>在云原生时代和容器化浪潮中，容器的日志采集是一个看起来不起眼却又无法忽视的重要议题。对于容器日志采集我们常用的工具有filebeat和fluentd，两者对比各有优劣，相比基于ruby的fluentd，考虑到可定制性，我们一般默认选择golang技术栈的filbeat作为主力的日志采集agent。</em><br><em>相比较传统的日志采集方式，容器化下单节点会运行更多的服务，负载也会有更短的生命周期，而这些更容易对日志采集agent造成压力，虽然filebeat足够轻量级和高性能，但如果不了解filebeat的机制，不合理的配置filebeat，实际的生产环境使用中可能也会给我们带来意想不到的麻烦和难题。</em></p>
</blockquote>
<h5 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h5><p>日志采集的功能看起来不复杂，主要功能无非就是找到配置的日志文件，然后读取并处理，发送至相应的后端如elasticsearch,kafka等。<br>filebeat官网有张示意图，如下所示：</p>
<p><img src="https://i.loli.net/2020/12/03/sYrzIGT9fkUD6eA.jpg" alt="v2-c93cd393aea675431432a2a4974524b7_1440w.jpg">]</p>
<p>针对每个日志文件，filebeat都会启动一个harvester协程，即一个goroutine，在该goroutine中不停的读取日志文件，直到文件的EOF末尾。一个最简单的表示采集目录的input配置大概如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filebeat.inputs:</span><br><span class="line">- type: log</span><br><span class="line">  # Paths that should be crawled and fetched. Glob based paths.</span><br><span class="line">  paths:</span><br><span class="line">    - &#x2F;var&#x2F;log&#x2F;*.log</span><br></pre></td></tr></table></figure>

<p>不同的harvester goroutine采集到的日志数据都会发送至一个全局的队列queue中，queue的实现有两种：基于内存和基于磁盘的队列，目前基于磁盘的队列还是处于alpha阶段，filebeat默认启用的是基于内存的缓存队列。<br>每当队列中的数据缓存到一定的大小或者超过了定时的时间（默认1s)，会被注册的client从队列中消费，发送至配置的后端。目前可以设置的client有kafka、elasticsearch、redis等。</p>
<p>虽然这一切看着挺简单，但在实际使用中，我们还是需要考虑更多的问题，例如：</p>
<ul>
<li>日志文件是如何被filbebeat发现又是如何被采集的？</li>
<li>filebeat是如何确保日志采集发送到远程的存储中，不丢失一条数据的？</li>
<li>如果filebeat挂掉，下次采集如何确保从上次的状态开始而不会重新采集所有日志？</li>
<li>filebeat的内存或者cpu占用过多，该如何分析解决？</li>
<li>filebeat如何支持docker和kubernetes，如何配置容器化下的日志采集？</li>
<li>想让filebeat采集的日志发送至的后端存储，如果原生不支持，怎样定制化开发？</li>
</ul>
<p>这些均需要对filebeat有更深入的理解，下面让我们跟随filebeat的源码一起探究其中的实现机制。</p>
<h5 id="一条日志是如何被采集的"><a href="#一条日志是如何被采集的" class="headerlink" title="一条日志是如何被采集的"></a>一条日志是如何被采集的</h5><p>filebeat源码归属于beats项目，而beats项目的设计初衷是为了采集各类的数据，所以beats抽象出了一个libbeat库，基于libbeat我们可以快速的开发实现一个采集的工具，除了filebeat，还有像metricbeat、packetbeat等官方的项目也是在beats工程中。<br>如果我们大致看一下代码就会发现，libbeat已经实现了内存缓存队列memqueue、几种output日志发送客户端，数据的过滤处理processor等通用功能，而filebeat只需要实现日志文件的读取等和日志相关的逻辑即可。</p>
<p>从代码的实现角度来看，filebeat大概可以分以下几个模块：</p>
<ul>
<li><p>input: 找到配置的日志文件，启动harvester</p>
</li>
<li><p>harvester: 读取文件，发送至spooler - spooler: 缓存日志数据，直到可以发送至publisher</p>
</li>
<li><p>publisher: 发送日志至后端，同时通知registrar</p>
</li>
<li><p>registrar: 记录日志文件被采集的状态</p>
<h6 id="1-找到日志文件"><a href="#1-找到日志文件" class="headerlink" title="1. 找到日志文件"></a>1. 找到日志文件</h6><p>对于日志文件的采集和生命周期管理，filebeat抽象出一个Crawler的结构体， 在filebeat启动后，crawler会根据配置创建，然后遍历并运行每个input：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for _, inputConfig :&#x3D; range c.inputConfigs &#123;</span><br><span class="line">        err :&#x3D; c.startInput(pipeline, inputConfig, r.GetStates())</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>在每个input运行的逻辑里，首先会根据配置获取匹配的日志文件，需要注意的是，这里的匹配方式并非正则，而是采用linux glob的规则，和正则还是有一些区别。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matches, err :&#x3D; filepath.Glob(path)</span><br></pre></td></tr></table></figure>

<p>获取到了所有匹配的日志文件之后，会经过一些复杂的过滤，例如如果配置了<code>exclude_files</code>则会忽略这类文件，同时还会查询文件的状态，如果文件的最近一次修改时间大于<code>ignore_older</code>的配置，也会不去采集该文件。</p>
<h6 id="2-读取日志文件"><a href="#2-读取日志文件" class="headerlink" title="2. 读取日志文件"></a>2. 读取日志文件</h6><p>匹配到最终需要采集的日志文件之后，filebeat会对每个文件启动harvester goroutine，在该goroutine中不停的读取日志，并发送给内存缓存队列memqueue。<br>在<code>(h *Harvester) Run()</code>方法中，我们可以看到这么一个无限循环，省略了一些逻辑的代码如下所示：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">for &#123;</span><br><span class="line">        message, err :&#x3D; h.reader.Next()</span><br><span class="line">        if err !&#x3D; nil &#123;</span><br><span class="line">            switch err &#123;</span><br><span class="line">            case ErrFileTruncate:</span><br><span class="line">                logp.Info(&quot;File was truncated. Begin reading file from offset 0: %s&quot;, h.state.Source)</span><br><span class="line">                h.state.Offset &#x3D; 0</span><br><span class="line">                filesTruncated.Add(1)</span><br><span class="line">            case ErrRemoved:</span><br><span class="line">                logp.Info(&quot;File was removed: %s. Closing because close_removed is enabled.&quot;, h.state.Source)</span><br><span class="line">            case ErrRenamed:</span><br><span class="line">                logp.Info(&quot;File was renamed: %s. Closing because close_renamed is enabled.&quot;, h.state.Source)</span><br><span class="line">            case ErrClosed:</span><br><span class="line">                logp.Info(&quot;Reader was closed: %s. Closing.&quot;, h.state.Source)</span><br><span class="line">            case io.EOF:</span><br><span class="line">                logp.Info(&quot;End of file reached: %s. Closing because close_eof is enabled.&quot;, h.state.Source)</span><br><span class="line">            case ErrInactive:</span><br><span class="line">                logp.Info(&quot;File is inactive: %s. Closing because close_inactive of %v reached.&quot;, h.state.Source, h.config.CloseInactive)</span><br><span class="line">            default:</span><br><span class="line">                logp.Err(&quot;Read line error: %v; File: %v&quot;, err, h.state.Source)</span><br><span class="line">            &#125;</span><br><span class="line">            return nil</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">        if !h.sendEvent(data, forwarder) &#123;</span><br><span class="line">            return nil</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，reader.Next()方法会不停的读取日志，如果没有返回异常，则发送日志数据到缓存队列中。<br>返回的异常有几种类型，除了读取到EOF外，还会有例如文件一段时间不活跃等情况发生会使harvester goroutine退出，不再采集该文件，并关闭文件句柄。<br>filebeat为了防止占据过多的采集日志文件的文件句柄，默认的<code>close_inactive</code>参数为5min，如果日志文件5min内没有被修改，上面代码会进入ErrInactive的case，之后该harvester goroutine会被关闭。<br>这种场景下还需要注意的是，如果某个文件日志采集中被移除了，但是由于此时被filebeat保持着文件句柄，文件占据的磁盘空间会被保留直到harvester goroutine结束。</p>
<h6 id="3-缓存队列"><a href="#3-缓存队列" class="headerlink" title="3. 缓存队列"></a>3. 缓存队列</h6><p>在memqueue被初始化时，filebeat会根据配置<code>min_event</code>是否大于1创建BufferingEventLoop或者DirectEventLoop，一般默认都是BufferingEventLoop，即带缓冲的队列。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">type bufferingEventLoop struct &#123;</span><br><span class="line">    broker *Broker</span><br><span class="line"></span><br><span class="line">    buf        *batchBuffer</span><br><span class="line">    flushList  flushList</span><br><span class="line">    eventCount int</span><br><span class="line"></span><br><span class="line">    minEvents    int</span><br><span class="line">    maxEvents    int</span><br><span class="line">    flushTimeout time.Duration</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; active broker API channels</span><br><span class="line">    events    chan pushRequest</span><br><span class="line">    get       chan getRequest</span><br><span class="line">    pubCancel chan producerCancelRequest</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; ack handling</span><br><span class="line">    acks        chan int      &#x2F;&#x2F; ackloop -&gt; eventloop : total number of events ACKed by outputs</span><br><span class="line">    schedACKS   chan chanList &#x2F;&#x2F; eventloop -&gt; ackloop : active list of batches to be acked</span><br><span class="line">    pendingACKs chanList      &#x2F;&#x2F; ordered list of active batches to be send to the ackloop</span><br><span class="line">    ackSeq      uint          &#x2F;&#x2F; ack batch sequence number to validate ordering</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; buffer flush timer state</span><br><span class="line">    timer *time.Timer</span><br><span class="line">    idleC &lt;-chan time.Time</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>BufferingEventLoop是一个实现了Broker、带有各种channel的结构，主要用于将日志发送至consumer消费。 BufferingEventLoop的run方法中，同样是一个无限循环，这里可以认为是一个日志事件的调度中心。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">for &#123;</span><br><span class="line">        select &#123;</span><br><span class="line">        case &lt;-broker.done:</span><br><span class="line">            return</span><br><span class="line">        case req :&#x3D; &lt;-l.events: &#x2F;&#x2F; producer pushing new event</span><br><span class="line">            l.handleInsert(&amp;req)</span><br><span class="line">        case req :&#x3D; &lt;-l.get: &#x2F;&#x2F; consumer asking for next batch</span><br><span class="line">            l.handleConsumer(&amp;req)</span><br><span class="line">        case count :&#x3D; &lt;-l.acks:</span><br><span class="line">            l.handleACK(count)</span><br><span class="line">        case &lt;-l.idleC:</span><br><span class="line">            l.idleC &#x3D; nil</span><br><span class="line">            l.timer.Stop()</span><br><span class="line">            if l.buf.length() &gt; 0 &#123;</span><br><span class="line">                l.flushBuffer()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>上文中harvester goroutine每次读取到日志数据之后，最终会被发送至bufferingEventLoop中的<code>events chan pushRequest</code> channel，然后触发上面<code>req := &lt;-l.events</code>的case，handleInsert方法会把数据添加至bufferingEventLoop的buf中，buf即memqueue实际缓存日志数据的队列，如果buf长度超过配置的最大值或者bufferingEventLoop中的timer定时器触发了<code>case &lt;-l.idleC</code>，均会调用flushBuffer()方法。<br>flushBuffer()又会触发<code>req := &lt;-l.get</code>的case，然后运行handleConsumer方法，该方法中最重要的是这一句代码：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req.resp &lt;- getResponse&#123;ackChan, events&#125;</span><br></pre></td></tr></table></figure>

<p>这里获取到了consumer消费者的response channel，然后发送数据给这个channel。真正到这，才会触发consumer对memqueue的消费。所以，其实memqueue并非一直不停的在被consumer消费，而是在memqueue通知consumer的时候才被消费，我们可以理解为一种脉冲式的发送。</p>
<h6 id="4-消费队列"><a href="#4-消费队列" class="headerlink" title="4. 消费队列"></a>4. 消费队列</h6><p>实际上，早在filebeat初始化的时候，就已经创建了一个eventConsumer并在loop无限循环方法里试图从Broker中获取日志数据。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">for &#123;</span><br><span class="line">        if !paused &amp;&amp; c.out != nil &amp;&amp; consumer != nil &amp;&amp; batch == nil &#123;</span><br><span class="line">            out = c.out.workQueue</span><br><span class="line">            queueBatch, err := consumer.Get(c.out.batchSize)</span><br><span class="line">            ...</span><br><span class="line">            batch = newBatch(c.ctx, queueBatch, c.out.timeToLive)</span><br><span class="line">        &#125;</span><br><span class="line">        ...</span><br><span class="line">        select &#123;</span><br><span class="line">        case &lt;-c.done:</span><br><span class="line">            return</span><br><span class="line">        case sig := &lt;-c.sig:</span><br><span class="line">            handleSignal(sig)</span><br><span class="line">        case out &lt;- batch:</span><br><span class="line">            batch = nil</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>上面consumer.Get就是消费者consumer从Broker中获取日志数据，然后发送至out的channel中被output client发送，我们看一下Get方法里的核心代码：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">select &#123;</span><br><span class="line">    case c.broker.requests &lt;- getRequest&#123;sz: sz, resp: c.resp&#125;:</span><br><span class="line">    case &lt;-c.done:</span><br><span class="line">        return nil, io.EOF</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // if request has been send, we do have to wait for a response</span><br><span class="line">    resp := &lt;-c.resp</span><br><span class="line">    return &amp;batch&#123;</span><br><span class="line">        consumer: c,</span><br><span class="line">        events:   resp.buf,</span><br><span class="line">        ack:      resp.ack,</span><br><span class="line">        state:    batchActive,</span><br><span class="line">    &#125;, nil</span><br></pre></td></tr></table></figure>

<p>getRequest的结构如下：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type getRequest struct &#123;</span><br><span class="line">    sz   int              // request sz events from the broker</span><br><span class="line">    resp chan getResponse // channel to send response to</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>getResponse的结构：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type getResponse struct &#123;</span><br><span class="line">    ack *ackChan</span><br><span class="line">    buf []publisher.Event</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>getResponse里包含了日志的数据，而getRequest包含了一个发送至消费者的channel。<br>在上文bufferingEventLoop缓冲队列的handleConsumer方法里接收到的参数为getRequest，里面包含了consumer请求的getResponse channel。<br>如果handleConsumer不发送数据，consumer.Get方法会一直阻塞在select中，直到flushBuffer，consumer的getResponse channel才会接收到日志数据。</p>
<h6 id="5-发送日志"><a href="#5-发送日志" class="headerlink" title="5. 发送日志"></a>5. 发送日志</h6><p>在创建beats时，会创建一个clientWorker，clientWorker的run方法中，会不停的从consumer发送的channel里读取日志数据，然后调用client.Publish批量发送日志。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func (w *clientWorker) run() &#123;</span><br><span class="line">    for !w.closed.Load() &#123;</span><br><span class="line">        for batch := range w.qu &#123;</span><br><span class="line">            if err := w.client.Publish(batch); err != nil &#123;</span><br><span class="line">                return</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>libbeats库中包含了kafka、elasticsearch、logstash等几种client，它们均实现了client接口：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type Client interface &#123;</span><br><span class="line">    Close() error</span><br><span class="line">    Publish(publisher.Batch) error</span><br><span class="line">    String() string</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然最重要的是实现Publish接口，然后将日志发送出去。</p>
<p>实际上，filebeat中日志数据在各种channel里流转的设计还是比较复杂和繁琐的，笔者也是研究了好久、画了很长的架构图才理清楚其中的逻辑。 这里抽出了一个简化后的图以供参考：</p>
<p><img src="https://i.loli.net/2020/12/03/vNS7wsAWfJoDTda.jpg" alt="v2-af4922d40750257351b3d08cc31cbc53_r.jpg"></p>
<h5 id="如何保证at-least-once"><a href="#如何保证at-least-once" class="headerlink" title="如何保证at least once"></a>如何保证at least once</h5><p>filebeat维护了一个registry文件在本地的磁盘，该registry文件维护了所有已经采集的日志文件的状态。 实际上，每当日志数据发送至后端成功后，会返回ack事件。filebeat启动了一个独立的registry协程负责监听该事件，接收到ack事件后会将日志文件的State状态更新至registry文件中，State中的Offset表示读取到的文件偏移量，所以filebeat会保证Offset记录之前的日志数据肯定被后端的日志存储接收到。<br>State结构如下所示：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">type State struct &#123;</span><br><span class="line">    Id          string            `json:&quot;-&quot;` // local unique id to make comparison more efficient</span><br><span class="line">    Finished    bool              `json:&quot;-&quot;` // harvester state</span><br><span class="line">    Fileinfo    os.FileInfo       `json:&quot;-&quot;` // the file info</span><br><span class="line">    Source      string            `json:&quot;source&quot;`</span><br><span class="line">    Offset      int64             `json:&quot;offset&quot;`</span><br><span class="line">    Timestamp   time.Time         `json:&quot;timestamp&quot;`</span><br><span class="line">    TTL         time.Duration     `json:&quot;ttl&quot;`</span><br><span class="line">    Type        string            `json:&quot;type&quot;`</span><br><span class="line">    Meta        map[string]string `json:&quot;meta&quot;`</span><br><span class="line">    FileStateOS file.StateOS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>记录在registry文件中的数据大致如下所示：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&quot;source&quot;:&quot;/tmp/aa.log&quot;,&quot;offset&quot;:48,&quot;timestamp&quot;:&quot;2019-07-03T13:54:01.298995+08:00&quot;,&quot;ttl&quot;:-1,&quot;type&quot;:&quot;log&quot;,&quot;meta&quot;:null,&quot;FileStateOS&quot;:&#123;&quot;inode&quot;:7048952,&quot;device&quot;:16777220&#125;&#125;]</span><br></pre></td></tr></table></figure>

<p>由于文件可能会被改名或移动，filebeat会根据inode和设备号来标志每个日志文件。<br>如果filebeat异常重启，每次采集harvester启动的时候都会读取registry文件，从上次记录的状态继续采集，确保不会从头开始重复发送所有的日志文件。<br>当然，如果日志发送过程中，还没来得及返回ack，filebeat就挂掉，registry文件肯定不会更新至最新的状态，那么下次采集的时候，这部分的日志就会重复发送，所以这意味着filebeat只能保证at least once，无法保证不重复发送。<br>还有一个比较异常的情况是，linux下如果老文件被移除，新文件马上创建，很有可能它们有相同的inode，而由于filebeat根据inode来标志文件记录采集的偏移，会导致registry里记录的其实是被移除的文件State状态，这样新的文件采集却从老的文件Offset开始，从而会遗漏日志数据。<br>为了尽量避免inode被复用的情况，同时防止registry文件随着时间增长越来越大，建议使用clean_inactive和clean_remove配置将长时间未更新或者被删除的文件State从registry中移除。</p>
<p>同时我们可以发现在harvester读取日志中，会更新registry的状态处理一些异常场景。例如，如果一个日志文件被清空，filebeat会在下一次Reader.Next方法中返回ErrFileTruncate异常，将inode标志文件的Offset置为0，结束这次harvester，重新启动新的harvester，虽然文件不变，但是registry中的Offset为0，采集会从头开始。</p>
<p>特别注意的是，如果使用容器部署filebeat，需要将registry文件挂载到宿主机上，否则容器重启后registry文件丢失，会使filebeat从头开始重复采集日志文件。</p>
<h5 id="filebeat自动reload更新"><a href="#filebeat自动reload更新" class="headerlink" title="filebeat自动reload更新"></a>filebeat自动reload更新</h5><p>目前filebeat支持reload input配置，module配置，但reload的机制只有定时更新。<br>在配置中打开reload.enable之后，还可以配置reload.period表示自动reload配置的时间间隔。<br>filebeat在启动时，会创建一个专门用于reload的协程。对于每个正在运行的harvester，filebeat会将其加入一个全局的Runner列表，每次到了定时的间隔后，会触发一次配置文件的diff判断，如果是需要停止的加入stopRunner列表，然后逐个关闭，新的则加入startRunner列表，启动新的Runner。</p>
<h5 id="filebeat对kubernetes的支持"><a href="#filebeat对kubernetes的支持" class="headerlink" title="filebeat对kubernetes的支持"></a>filebeat对kubernetes的支持</h5><p>filebeat官方文档提供了在kubernetes下基于daemonset的部署方式，最主要的一个配置如下所示：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- type: docker</span><br><span class="line">      containers.ids:</span><br><span class="line">      - &quot;*&quot;</span><br><span class="line">      processors:</span><br><span class="line">        - add_kubernetes_metadata:</span><br><span class="line">            in_cluster: true</span><br></pre></td></tr></table></figure>

<p>即设置输入input为docker类型。由于所有的容器的标准输出日志默认都在节点的<code>/var/lib/docker/containers/&lt;containerId&gt;/*-json.log</code>路径，所以本质上采集的是这类日志文件。<br>和传统的部署方式有所区别的是，如果服务部署在kubernetes上，我们查看和检索日志的维度不能仅仅局限于节点和服务，还需要有podName，containerName等，所以每条日志我们都需要打标增加kubernetes的元信息才发送至后端。<br>filebeat会在配置中增加了add_kubernetes_metadata的processor的情况下，启动监听kubernetes的watch服务，监听所有kubernetes pod的变更，然后将归属本节点的pod最新的事件同步至本地的缓存中。<br>节点上一旦发生容器的销毁创建，/var/lib/docker/containers/下会有目录的变动，filebeat根据路径提取出containerId，再根据containerId从本地的缓存中找到pod信息，从而可以获取到podName、label等数据，并加到日志的元信息fields中。<br>filebeat还有一个beta版的功能autodiscover，autodiscover的目的是把分散到不同节点上的filebeat配置文件集中管理。目前也支持kubernetes作为provider，本质上还是监听kubernetes事件然后采集docker的标准输出文件。<br>大致架构如下所示：</p>
<p><img src="https://i.loli.net/2020/12/03/lgyNXG5MsHW3vDS.jpg" alt="v2-8e12038a5d6c25479b481186afcfd29d_r.jpg"></p>
<p>但是在实际生产环境使用中，仅采集容器的标准输出日志还是远远不够，我们往往还需要采集容器挂载出来的自定义日志目录，还需要控制每个服务的日志采集方式以及更多的定制化功能。</p>
<p>在轻舟容器云上，我们自研了一个监听kubernetes事件自动生成filebeat配置的agent，通过CRD的方式，支持自定义容器内部日志目录、支持自定义fields、支持多行读取等功能。同时可在kubernetes上统一管理各种日志配置，而且无需用户感知pod的创建销毁和迁移，自动完成各种场景下的日志配置生成和更新。</p>
<h5 id="性能分析与调优"><a href="#性能分析与调优" class="headerlink" title="性能分析与调优"></a>性能分析与调优</h5><p>虽然beats系列主打轻量级，虽然用golang写的filebeat的内存占用确实比较基于jvm的logstash等好太多，但是事实告诉我们其实没那么简单。<br>正常启动filebeat，一般确实只会占用3、40MB内存，但是在轻舟容器云上偶发性的我们也会发现某些节点上的filebeat容器内存占用超过配置的pod limit限制（一般设置为200MB），并且不停的触发的OOM。<br>究其原因，一般容器化环境中，特别是裸机上运行的容器个数可能会比较多，导致创建大量的harvester去采集日志。如果没有很好的配置filebeat，会有较大概率导致内存急剧上升。<br>当然，filebeat内存占据较大的部分还是memqueue，所有采集到的日志都会先发送至memqueue聚集，再通过output发送出去。每条日志的数据在filebeat中都被组装为event结构，filebeat默认配置的memqueue缓存的event个数为4096，可通过<code>queue.mem.events</code>设置。默认最大的一条日志的event大小限制为10MB，可通过<code>max_bytes</code>设置。<code>4096 * 10MB = 40GB</code>，可以想象，极端场景下，filebeat至少占据40GB的内存。特别是配置了multiline多行模式的情况下，如果multiline配置有误，单个event误采集为上千条日志的数据，很可能导致memqueue占据了大量内存，致使内存爆炸。<br>所以，合理的配置日志文件的匹配规则，限制单行日志大小，根据实际情况配置memqueue缓存的个数，才能在实际使用中规避filebeat的内存占用过大的问题。</p>
<h5 id="如何对filebeat进行扩展开发"><a href="#如何对filebeat进行扩展开发" class="headerlink" title="如何对filebeat进行扩展开发"></a>如何对filebeat进行扩展开发</h5><p>一般情况下filebeat可满足大部分的日志采集需求，但是仍然避免不了一些特殊的场景需要我们对filebeat进行定制化开发，当然filebeat本身的设计也提供了良好的扩展性。<br>beats目前只提供了像elasticsearch、kafka、logstash等几类output客户端，如果我们想要filebeat直接发送至其他后端，需要定制化开发自己的output。同样，如果需要对日志做过滤处理或者增加元信息，也可以自制processor插件。<br>无论是增加output还是写个processor，filebeat提供的大体思路基本相同。一般来讲有3种方式：</p>
<ol>
<li>直接fork filebeat，在现有的源码上开发。output或者processor都提供了类似Run、Stop等的接口，只需要实现该类接口，然后在init方法中注册相应的插件初始化方法即可。当然，由于golang中init方法是在import包时才被调用，所以需要在初始化filebeat的代码中手动import。</li>
<li>复制一份filebeat的main.go，import我们自研的插件库，然后重新编译。本质上和方式1区别不大。</li>
<li>filebeat还提供了基于golang plugin的插件机制，需要把自研的插件编译成.so共享链接库，然后在filebeat启动参数中通过-plugin指定库所在路径。不过实际上一方面golang plugin还不够成熟稳定，一方面自研的插件依然需要依赖相同版本的libbeat库，而且还需要相同的golang版本编译，坑可能更多，不太推荐。</li>
</ol>

</article>

    <div class="pagenator post-pagenator">
    
    

    
    <p>last update time 2020-12-03</p>
    
    
        <a class="extend next post-next" href="/2020/09/01/High-Performance-TiDB-Lesson-3/">next</a>
    
    </div>

    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:binginx@126.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/sdaulibin" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © binginx 2015 - 2022
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
	<span>
	    <a target="_blank" rel="noopener" href="http://beian.miit.gov.cn">鲁ICP备2021008248号</a>
	</span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>

    </div>
</body>
</html>
